{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0115fba9-0e35-4f6d-8832-e63882eb7bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEXT MODE ===\n",
      "Text Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.92      0.79      0.85       462\n",
      "        fear       0.85      0.74      0.79       415\n",
      "         joy       0.81      0.96      0.88      1176\n",
      "        love       0.86      0.64      0.73       318\n",
      "     sadness       0.89      0.94      0.91      1092\n",
      "    surprise       0.87      0.50      0.63       137\n",
      "\n",
      "    accuracy                           0.86      3600\n",
      "   macro avg       0.87      0.76      0.80      3600\n",
      "weighted avg       0.86      0.86      0.85      3600\n",
      "\n",
      "Text Accuracy: 85.75%\n",
      "\n",
      "=== FACE MODE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 9816/9816 [00:23<00:00, 421.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2455/2455 [00:04<00:00, 603.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3068/3068 [00:04<00:00, 656.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.61      0.54       236\n",
      "           2       0.23      0.37      0.28        52\n",
      "           3       0.24      0.33      0.27       158\n",
      "           4       0.79      0.79      0.79       983\n",
      "           5       0.42      0.38      0.40       395\n",
      "           6       0.52      0.45      0.48       155\n",
      "           7       0.53      0.41      0.46       476\n",
      "\n",
      "    accuracy                           0.57      2455\n",
      "   macro avg       0.46      0.48      0.46      2455\n",
      "weighted avg       0.58      0.57      0.58      2455\n",
      "\n",
      "Validation Accuracy: 57.43%\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.63      0.56       329\n",
      "           2       0.25      0.39      0.31        74\n",
      "           3       0.20      0.31      0.24       160\n",
      "           4       0.79      0.81      0.80      1185\n",
      "           5       0.50      0.46      0.47       478\n",
      "           6       0.46      0.43      0.44       162\n",
      "           7       0.65      0.47      0.55       680\n",
      "\n",
      "    accuracy                           0.61      3068\n",
      "   macro avg       0.48      0.50      0.48      3068\n",
      "weighted avg       0.62      0.61      0.61      3068\n",
      "\n",
      "Test Accuracy: 60.56%\n"
     ]
    }
   ],
   "source": [
    "# Emotion Detection ML Web App - Dual Mode (Text + Face)\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from skimage.feature import hog\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# ---------------------\n",
    "# SECTION 1: TEXT-BASED EMOTION DETECTION\n",
    "# ---------------------\n",
    "print(\"=== TEXT MODE ===\")\n",
    "\n",
    "text_path = \"text_dataset\"\n",
    "train_file = os.path.join(text_path, \"train.txt\")\n",
    "val_file = os.path.join(text_path, \"val.txt\")\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.exists(train_file) or not os.path.exists(val_file):\n",
    "    raise FileNotFoundError(f\"Missing files in {text_path}. Ensure 'train.txt' and 'val.txt' exist.\")\n",
    "\n",
    "# Load text data with correct delimiter\n",
    "df_train = pd.read_csv(train_file, sep=\";\", names=[\"text\", \"label\"])\n",
    "df_val = pd.read_csv(val_file, sep=\";\", names=[\"text\", \"label\"])\n",
    "\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_train.dropna(subset=['text', 'label'], inplace=True)\n",
    "df_val.dropna(subset=['text', 'label'], inplace=True)\n",
    "\n",
    "# Strip and remove empty text after stripping whitespace\n",
    "df_train['text'] = df_train['text'].astype(str).str.strip()\n",
    "df_val['text'] = df_val['text'].astype(str).str.strip()\n",
    "df_train = df_train[df_train['text'].str.len() > 0]\n",
    "df_val = df_val[df_val['text'].str.len() > 0]\n",
    "# Combine for vectorization\n",
    "df_all = pd.concat([df_train, df_val], axis=0)\n",
    "X_text = df_all['text']\n",
    "y_text = df_all['label']\n",
    "\n",
    "# Text Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "try:\n",
    "    X_vect = vectorizer.fit_transform(X_text).toarray()\n",
    "except ValueError as e:\n",
    "    print(\"Vectorization failed:\", e)\n",
    "    print(\"Sample input texts:\", X_text.head())\n",
    "    raise\n",
    "\n",
    "# Train/test split\n",
    "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(\n",
    "    X_vect, y_text, test_size=0.2, random_state=42)\n",
    "\n",
    "# Drop NaNs if they exist (extra safeguard)\n",
    "valid_idx = y_train_text.notnull()\n",
    "X_train_text = X_train_text[valid_idx]\n",
    "y_train_text = y_train_text[valid_idx]\n",
    "\n",
    "valid_idx = y_test_text.notnull()\n",
    "X_test_text = X_test_text[valid_idx]\n",
    "y_test_text = y_test_text[valid_idx]\n",
    "\n",
    "# Train Logistic Regression\n",
    "text_model = LogisticRegression(max_iter=1000)\n",
    "text_model.fit(X_train_text, y_train_text)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_text = text_model.predict(X_test_text)\n",
    "print(\"Text Classification Report:\\n\", metrics.classification_report(y_test_text, y_pred_text))\n",
    "print(\"Text Accuracy: {:.2f}%\".format(metrics.accuracy_score(y_test_text, y_pred_text) * 100))\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# SECTION 3: FACE-BASED EMOTION DETECTION\n",
    "# ---------------------\n",
    "print(\"\\n=== FACE MODE ===\")\n",
    "\n",
    "# Paths\n",
    "face_root = \"face_dataset\"\n",
    "train_csv_path = os.path.join(face_root, \"train_labels.csv\")\n",
    "test_csv_path = os.path.join(face_root, \"test_labels.csv\")\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.exists(train_csv_path) or not os.path.exists(test_csv_path):\n",
    "    raise FileNotFoundError(f\"Missing face CSV files in {face_root}. Ensure 'train_labels.csv' and 'test_labels.csv' exist.\")\n",
    "\n",
    "# Load CSVs\n",
    "full_train_csv = pd.read_csv(train_csv_path)\n",
    "test_csv = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Optional: Enable lite mode\n",
    "lite_mode = False\n",
    "if lite_mode:\n",
    "    full_train_csv = full_train_csv.sample(800, random_state=42)\n",
    "    test_csv = test_csv.sample(200, random_state=42)\n",
    "\n",
    "# Split into train and validation\n",
    "train_csv, val_csv = train_test_split(full_train_csv, test_size=0.2, random_state=42)\n",
    "\n",
    "# Parallel image processing function\n",
    "def process_image(row, base_path):\n",
    "    label = row['label']\n",
    "    filename = row['image']\n",
    "    img_path = os.path.join(face_root, base_path, str(label), filename)\n",
    "    if not os.path.exists(img_path):\n",
    "        return None, None\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return None, None\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "    hog_feat = hog(img_resized, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "    return hog_feat, label\n",
    "\n",
    "# Parallel loader\n",
    "def load_face_data_parallel(df, base_path):\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_image)(row, base_path) for _, row in tqdm(df.iterrows(), total=len(df)))\n",
    "    features, labels = zip(*[(f, l) for f, l in results if f is not None])\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Load features\n",
    "X_train_face, y_train_face = load_face_data_parallel(train_csv, \"DATASET/train\")\n",
    "X_val_face, y_val_face = load_face_data_parallel(val_csv, \"DATASET/train\")\n",
    "X_test_face, y_test_face = load_face_data_parallel(test_csv, \"DATASET/test\")\n",
    "\n",
    "# Validate loaded data\n",
    "if len(X_train_face) == 0 or len(X_test_face) == 0:\n",
    "    raise ValueError(\"Face data loading failed. Ensure image paths and directory structure are correct.\")\n",
    "\n",
    "# Scale features\n",
    "scaler_face = StandardScaler()\n",
    "X_train_face = scaler_face.fit_transform(X_train_face)\n",
    "X_val_face = scaler_face.transform(X_val_face)\n",
    "X_test_face = scaler_face.transform(X_test_face)\n",
    "\n",
    "# Train SVM\n",
    "face_model = SVC(kernel='linear', probability=True)\n",
    "face_model.fit(X_train_face, y_train_face)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_pred_val = face_model.predict(X_val_face)\n",
    "print(\"Validation Classification Report:\\n\", metrics.classification_report(y_val_face, y_pred_val))\n",
    "print(\"Validation Accuracy: {:.2f}%\".format(metrics.accuracy_score(y_val_face, y_pred_val) * 100))\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test = face_model.predict(X_test_face)\n",
    "print(\"Test Classification Report:\\n\", metrics.classification_report(y_test_face, y_pred_test))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(metrics.accuracy_score(y_test_face, y_pred_test) * 100))\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# SECTION 4: WRAPPER FUNCTIONS (FOR UI INTEGRATION)\n",
    "# ---------------------\n",
    "def predict_text_emotion(text_input):\n",
    "    vect_input = vectorizer.transform([text_input]).toarray()\n",
    "    return text_model.predict(vect_input)[0]\n",
    "\n",
    "def predict_face_emotion(img_path):\n",
    "    if not os.path.exists(img_path):\n",
    "        return \"Image not found.\"\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return \"Invalid image.\"\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "    hog_feat = hog(img_resized, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "    hog_feat = scaler_face.transform([hog_feat])\n",
    "    return face_model.predict(hog_feat)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4dd5f-bfeb-4e99-b86a-0b72324811e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af047c88-dd27-488e-985e-c725f0662b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20da0195-9b02-4018-934d-0783d799327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save text mode components\n",
    "joblib.dump(text_model, 'text_model.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "\n",
    "# Save face mode components\n",
    "joblib.dump(face_model, 'face_model.pkl')\n",
    "joblib.dump(scaler_face, 'face_scaler.pkl')\n",
    "\n",
    "print(\"✅ All models saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93099b69-7835-4395-9db8-90b39d23bef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
